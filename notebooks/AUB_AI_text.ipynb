{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AIcadamy Text Mining Hands on\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jXrI2Om-y9Od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download the arabic news dataset and unzip it into the machine running at google colab\n",
        "\n",
        "Note:\n",
        "The \"!\" runs a unix shell command\n",
        "\n",
        "\"wget\" is a utility to download data from a given URL.\n",
        "\n",
        "\"unzip\" allows us to upack the downloaded data."
      ],
      "metadata": {
        "id": "k6ZDemSZzG2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2NlEBjI7HmM",
        "outputId": "0c2b5256-b4b9-4527-bf81-9757e34910a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-27 11:57:38--  http://thomas.haschka.net/archive.zip\n",
            "Resolving thomas.haschka.net (thomas.haschka.net)... 149.202.48.113, 2001:41d0:401:3000::571b\n",
            "Connecting to thomas.haschka.net (thomas.haschka.net)|149.202.48.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68916418 (66M) [application/zip]\n",
            "Saving to: ‘archive.zip.2’\n",
            "\n",
            "archive.zip.2       100%[===================>]  65.72M  11.7MB/s    in 6.1s    \n",
            "\n",
            "2023-09-27 11:57:44 (10.8 MB/s) - ‘archive.zip.2’ saved [68916418/68916418]\n",
            "\n",
            "Archive:  archive.zip\n",
            "replace Culture/0000.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget http://thomas.haschka.net/archive.zip\n",
        "!unzip archive.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is classified into the following sections:\n",
        "\n",
        "- Culture\n",
        "- Finance\n",
        "- Medical\n",
        "- Politics\n",
        "- Religion\n",
        "- Sports\n",
        "- Tech\n",
        "\n",
        "as such we create a list covering these labels. And providing indices to it. As in python lists start to count at 0, we can identify Culture:0, Finance:1, Medical:2 etc."
      ],
      "metadata": {
        "id": "DGrn1NbAz1QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Culture\", \"Finance\", \"Medical\", \"Politics\", \"Religion\", \"Sports\", \"Tech\" ]"
      ],
      "metadata": {
        "id": "5H0asND17cia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is organized into individual text files, each covering a news article. We have therefore a folder structure like the following:\n",
        "\n",
        "/content/Culture/0001.txt ...\n",
        "You can click on the folder icon on the left and download a few samples to see what this files look like.\n",
        "\n",
        "the glob library will allow us to pars this structure with \"wildcards\"\n",
        "\n",
        "In the following code we load our dataset into python lists.\n",
        "\n",
        "X: in general contains the features: here the text\n",
        "\n",
        "Y: the targets, the news categories, here identified by [0-6]"
      ],
      "metadata": {
        "id": "EPpZoslT0cAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "bDg1IRsVAzhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0;\n",
        "X = []\n",
        "Y = []\n",
        "for label in labels:\n",
        "  files = glob.glob(\"./\" + label + \"/*.txt\")\n",
        "  for file in files:\n",
        "    f = open(file,\"r\")\n",
        "    X.append(f.read())\n",
        "    Y.append(l)\n",
        "  l = l+1"
      ],
      "metadata": {
        "id": "pdxjgZAXA8Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next section we transform our dataset into vectors, with the count vectorizer. A vector has the length of all unique occurances of each word. For each news article (sample) each word is counted, and the number of counts are updated in the vector discribing this news article."
      ],
      "metadata": {
        "id": "0_lrfQgb1-rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_counts = count_vect.fit_transform(X)\n",
        "X_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRjB_GK-B7oQ",
        "outputId": "f79221a3-ce95-4179-cbd9-19c42084b401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45500, 426055)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We further convert the vectors obtained with the tf-idf Transformer:\n",
        "\n",
        "tf: Is the term frequency. The term frequency is given for each word w in each news article a:\n",
        "\n",
        "tf(w,a)= number of occurances of w dived by the number of words in a\n",
        "\n",
        "idf: Is the inverse document frequency. It is given by the logarithm (in base 2 in general) of the fraction: Number of news articles in the dataset / Number of occurrences of the word in the dataset.  \n"
      ],
      "metadata": {
        "id": "___Rwe1v47xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tf_transformer = TfidfTransformer(use_idf=True).fit(X_counts)\n",
        "X_tfidf = tf_transformer.transform(X_counts)\n",
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7OotElwB9WQ",
        "outputId": "688bbe08-e163-4474-fe13-9efcc85d7ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45500, 426055)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We try two different classifiers that scikit learn proposes to us. For a comparision of classifiers see:\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
      ],
      "metadata": {
        "id": "M9FnfzPYrNml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split\n"
      ],
      "metadata": {
        "id": "cZmuiOJMD4MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use cross validation in order to compair the two different classifiers. You could try different other classifiers that you might find on the scikit-learn webpage. Be aware that the dataset is relatively large and few classifiers might work. Extra points for those that find one that does."
      ],
      "metadata": {
        "id": "AOPEeuNpr9SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "cv = ShuffleSplit(n_splits=10, train_size=0.5, test_size=0.5, random_state=42)\n",
        "\n",
        "names = ['Naive Bayes', 'Support Vector Machine']\n",
        "\n",
        "clfs = [MultinomialNB(),\n",
        "        SGDClassifier(loss='hinge', penalty='l2',\n",
        "                      alpha=1e-3, random_state=42,\n",
        "                      max_iter=5, tol=None)]\n",
        "\n",
        "for i in range(len(clfs)):\n",
        "  clf = clfs[i]\n",
        "  scores = cross_val_score(clf, X_tfidf, np.array(Y),cv=cv)\n",
        "  print(names[i] + \" %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvSdHpKjHaxE",
        "outputId": "4257bd81-7ff8-4b72-afb2-9b8ffd3ca50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes 0.96 (+/- 0.00)\n",
            "Support Vector Machine 0.97 (+/- 0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we tested the two different models we found that the support vector machine classifier works better then the naive bayes. We split the dataset just as we did it during the cross validation and build a functioning machine learning model, using the Pipeline functionnality of scikit-learn."
      ],
      "metadata": {
        "id": "QTaFkMjisbAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, np.array(Y), train_size=0.5, test_size=0.5, shuffle=True)"
      ],
      "metadata": {
        "id": "hfwC0cLGHhb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "u-RzteYfdwN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([('count',CountVectorizer()),\n",
        "                  ('tfidf',TfidfTransformer(use_idf=True)),\n",
        "                  ('svm', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                                        alpha=1e-3, random_state=42,\n",
        "                                        max_iter=5, tol=None))])"
      ],
      "metadata": {
        "id": "Ujamp8mKf30R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform the final training stage."
      ],
      "metadata": {
        "id": "l3EV36uOs6Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "xq54RM2BnkHP",
        "outputId": "e85b4833-0ff5-4bad-861d-268ee9da800e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('count', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('svm',\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;count&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;svm&#x27;,\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;count&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;svm&#x27;,\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.001, max_iter=5, random_state=42, tol=None)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We score the model a last time using the test set from the training/testset split and validate that the score is in accordance with the cross validation"
      ],
      "metadata": {
        "id": "uDbs-c4Es-sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedc3e90-9259-4b04-d779-903c594db83e",
        "id": "Z-OpogB7ngRi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9665934065934066"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":With the following text we predict that some arabic text copied from a sport news website"
      ],
      "metadata": {
        "id": "pNtAYT79tO2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code sample labels[model.precdict(['some_arabic_text'])[0]]\n",
        "labels[model.predict(['في خاتمة قضائية لقضية جديدة مرتبطة بالرموز الدينية في الأماكن العامة، وهو موضع نقاشات متكررة في فرنسا، حكم مجلس الشورى بأن الاتحاد الفرنسي لكرة القدم يمكنه سنّ القواعد التي يراها ضرورية \"لحسن سير\" المباريات، ما يبرر تالياً له منع ارتداء الحجاب في الملاعب.'])[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "65wCCgfGoxav",
        "outputId": "def3c78a-b0e5-4acc-f178-0a19cab797f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sports'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}